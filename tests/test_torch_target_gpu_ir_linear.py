import os
import pytest
import httpx

API_URL = os.environ.get("API_URL", "http://localhost:8000/generate_ir")

code = """
import torch
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(4, 4)

    def forward(self, x):
        return torch.relu(self.linear(x))

model = MyModel()
example_input = torch.randn(4, 4)
"""


def test_torch_nvptx_linear():
    payload = {
        "code": code,
        "ir_type": "nvptx",
        "custom_pipeline": [],
        "torch_mlir_opt": "",
        "mlir_opt": "",
        "mlir_translate": "",
        "llvm_opt": "",
        "llc": "",
        "user_tool": "",
        "dump_after_each_opt": False,
    }

    response = httpx.post(API_URL, json=payload)
    assert response.status_code == 200

    ir = response.json()["output"]

    assert "Generated by LLVM NVPTX Back-End" in ir
    assert ".visible .func  (.param .align 8 .b8 func_retval0[56]) main" in ir


def test_torch_nvptx_linear():
    payload = {
        "code": code,
        "ir_type": "amdgpu",
        "custom_pipeline": [],
        "torch_mlir_opt": "",
        "mlir_opt": "",
        "mlir_translate": "",
        "llvm_opt": "",
        "llc": "",
        "user_tool": "",
        "dump_after_each_opt": False,
    }

    response = httpx.post(API_URL, json=payload)
    assert response.status_code == 200

    ir = response.json()["output"]

    assert "amdgcn-amd-amdhsa--gfx700" in ir
    assert "main:" in ir


def test_torch_nvptx_linear():
    payload = {
        "code": code,
        "ir_type": "spirv",
        "custom_pipeline": [],
        "torch_mlir_opt": "",
        "mlir_opt": "",
        "mlir_translate": "",
        "llvm_opt": "",
        "llc": "",
        "user_tool": "",
        "dump_after_each_opt": False,
    }

    response = httpx.post(API_URL, json=payload)
    assert response.status_code == 200

    ir = response.json()["output"]

    assert "OpCapability Kernel" in ir
